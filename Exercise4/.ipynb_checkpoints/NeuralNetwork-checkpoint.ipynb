{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19039db9",
   "metadata": {},
   "source": [
    "# Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06210371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1360b1",
   "metadata": {},
   "source": [
    "### Load and Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fdbc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2     3     4     5    6    7    8    9   ...   54   55   56  \\\n",
       "0  0.0  0.0  5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0  0.0   \n",
       "3  0.0  0.0  7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    57   58    59    60    61   62   63  \n",
       "0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = load_digits()\n",
    "pd.DataFrame(mnist.data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "91d62614",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mnist.data\n",
    "y=mnist.target\n",
    "#X, x_val, y, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "m = y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2034739c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 10, figsize=(16, 6))\n",
    "for i in range(20):\n",
    "    axes[i//10, i %10].imshow(mnist.images[i], cmap='gray');\n",
    "    axes[i//10, i %10].axis('off')\n",
    "    axes[i//10, i %10].set_title(f\"target: {mnist.target[i]}\")\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac79061",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3ff56711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z.\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8392230",
   "metadata": {},
   "source": [
    "## Random Initialization\n",
    "\n",
    "When training networks, it is important to randomly initialize the parameters for symmetry breaking. One effective strategy for random initialization is to randomly select values for $\\Theta^{(l)}$ uniformly in the range $[-\\epsilon_{init}, \\epsilon_{init}]$. You should use $\\epsilon_{init} = 0.12$. This range of values ensures that the parameters are kept small and makes the learning more efficient.\n",
    "\n",
    "<div class=\"alert alert-box alert-warning\">\n",
    "One effective strategy for choosing $\\epsilon_{init}$ is to base it on the number of units in the network. A good choice of $\\epsilon_{init}$ is $\\epsilon_{init} = \\frac{\\sqrt{6}}{\\sqrt{L_{in} + L_{out}}}$ where $L_{in} = s_l$ and $L_{out} = s_{l+1}$ are the number of units in the layers adjacent to $\\Theta^{l}$.\n",
    "</div>\n",
    "\n",
    "Your job is to complete the function `randInitializeWeights` to initialize the weights for $\\Theta$. Modify the function by filling in the following code:\n",
    "\n",
    "```python\n",
    "# Randomly initialize the weights to small values\n",
    "W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "```\n",
    "Note that we give the function an argument for $\\epsilon$ with default value `epsilon_init = 0.12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5d62b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    \"\"\"\n",
    "    Randomly initialize the weights of a layer in a neural network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    L_in : int\n",
    "        Number of incomming connections.\n",
    "    \n",
    "    L_out : int\n",
    "        Number of outgoing connections. \n",
    "    \n",
    "    epsilon_init : float, optional\n",
    "        Range of values which the weight can take from a uniform \n",
    "        distribution.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W : array_like\n",
    "        The weight initialiatized to random values.  Note that W should\n",
    "        be set to a matrix of size(L_out, 1 + L_in) as\n",
    "        the first column of W handles the \"bias\" terms.\n",
    "    \"\"\"\n",
    "\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae16e5b",
   "metadata": {},
   "source": [
    "### Sigmoid Gradient\n",
    "The gradient for the sigmoid function can be\n",
    "computed as\n",
    "\n",
    "$$ g'(z) = \\frac{d}{dz} g(z) = g(z)\\left(1-g(z)\\right) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\text{sigmoid}(z) = g(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "[Derivative of Sigmoid Function](https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a39a0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the sigmoid function evaluated at z. \n",
    "    This should work regardless if z is a matrix or a vector. \n",
    "    In particular, if z is a vector or matrix, you should return\n",
    "    the gradient for each element.\n",
    "    \"\"\"\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "    g = sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc53936",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K} \\left[ - y_k^{(i)} \\log \\left( \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) - \\left( 1 - y_k^{(i)} \\right) \\log \\left( 1 - \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) \\right]$$\n",
    "\n",
    "**With Regularization** \n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m}\\sum_{k=1}^{K} \\left[ - y_k^{(i)} \\log \\left( \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) - \\left( 1 - y_k^{(i)} \\right) \\log \\left( 1 - \\left( h_\\theta \\left( x^{(i)} \\right) \\right)_k \\right) \\right] + \\frac{\\lambda}{2 m} \\left[ \\sum_{j=1}^{25} \\sum_{k=1}^{400} \\left( \\Theta_{j,k}^{(1)} \\right)^2 + \\sum_{j=1}^{10} \\sum_{k=1}^{25} \\left( \\Theta_{j,k}^{(2)} \\right)^2 \\right] $$\n",
    "\n",
    "K is the total number of possibles labels (10 here)\n",
    "m is no of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8ba02295",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size  = 64  # 8x8 Input Images of Digits\n",
    "hidden_layer_size = 15   # 25 hidden units\n",
    "num_labels = 10          # 10 labels, from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a6156a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1=randInitializeWeights(64,15)\n",
    "Theta2 = randInitializeWeights(15,10)\n",
    "Theta=np.concatenate([Theta1.ravel(), Theta2.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "47f15986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forProp(X,Theta1,Theta2,m):\n",
    "    '''Forward propagation for 3 layers Neural Network'''\n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    #Hidden layer\n",
    "    a2=sigmoid(a1.dot(Theta1.T))\n",
    "    a2=np.concatenate([np.ones((m,1)),a2],axis=1) #adding bias term in second layer\n",
    "    \n",
    "    #Output layer\n",
    "    a3=sigmoid(a2.dot(Theta2.T))\n",
    "    y_matrix = y.reshape(-1) #convert into single row vector\n",
    "    y_matrix = np.eye(num_labels)[y_matrix] #encode output layer with 1 and 0\n",
    "    \n",
    "    return a1,a2,a3,y_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "15265a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costNN(Theta,a3,y,lambda_=100):\n",
    "    #Calculating cost\n",
    "    Theta1 = np.reshape(Theta[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(Theta[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "    J = (-1/m) * (np.sum(y * np.log(a3) + (1-y) * np.log(1-a3))) #cost without regularization terms\n",
    "    #Adding regularization terms\n",
    "    reg = (lambda_/(2*m)) * (np.sum(np.square(Theta1[:, 1:])) + np.sum(np.square(Theta2[:, 1:])))\n",
    "    J = J + reg\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58f733",
   "metadata": {},
   "source": [
    "**Errors**\n",
    "1. For each output unit $k$ in layer 3 (the output layer), set \n",
    "$$\\delta_k^{(3)} = \\left(a_k^{(3)} - y_k \\right)$$\n",
    "where $y_k \\in \\{0, 1\\}$ indicates whether the current training example belongs to class $k$ $(y_k = 1)$, or if it belongs to a different class $(y_k = 0)$. You may find logical arrays helpful for this task (explained in the previous programming exercise).\n",
    "\n",
    "1. For the hidden layer $l = 2$, set \n",
    "$$ \\delta^{(2)} = \\left( \\Theta^{(2)} \\right)^T \\delta^{(3)} * g'\\left(z^{(2)} \\right)$$\n",
    "Note that the symbol $*$ performs element wise multiplication in `numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8059894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(a1,a2,a3,Theta,lambda_=100):\n",
    "    Theta1 = np.reshape(Theta[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(Theta[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "    del3 = a3-y_matrix\n",
    "    \n",
    "    del2 = np.dot(del3, Theta2[:, 1:]) * sigmoidGradient(np.dot(a1, Theta1.T))  # exclude bias unit because it has no connection with input layer\n",
    "    \n",
    "    Delta1 = np.dot(del2.T, a1)  \n",
    "    Delta2 = np.dot(del3.T, a2)\n",
    "    \n",
    "    #Calculating gradient term\n",
    "    Theta2_grad = (1/m) * Delta2\n",
    "    Theta1_grad = (1/m) * Delta1\n",
    "    \n",
    "    # Add regularization terms excluding the Theta columns for the bias units\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_/m) * Theta2[:, 1:]\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_/m) * Theta1[:, 1:]\n",
    "    \n",
    "    # Unroll gradients\n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff511c",
   "metadata": {},
   "source": [
    "Gradient checking will assure that our backpropagation works as intended. We can approximate the derivative of our cost function with:\n",
    "\n",
    "$$ J\\left( \\theta \\right) \\approx \\frac{J\\left( \\theta+\\epsilon\\right) - J\\left( \\theta-\\epsilon \\right)}{2\\epsilon} $$\n",
    "\n",
    "With multiple theta matrices, we can approximate the derivative with respect to Î˜jÎ˜_jÎ˜jâ€‹ as follows:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\Theta_{ij}^{(l)}} J(\\Theta)\\approx \\dfrac{J(\\Theta_1, \\dots, \\Theta_j + \\epsilon, \\dots, \\Theta_n) - J(\\Theta_1, \\dots, \\Theta_j - \\epsilon, \\dots, \\Theta_n)}{2\\epsilon}$$\n",
    "\n",
    "A small value for Ïµ(epsilon) such as ${\\epsilon = 10^{-4}}$, guarantees that the math works out properly. If the value for Ïµ\\epsilonÏµ is too small, we can end up with numerical problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c6594922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientCheck(Theta1,Theta2,a3,opLayer,lambda_=100):\n",
    "    epsilon = 0.0004;\n",
    "    Theta=np.concatenate([Theta1.ravel(), Theta2.ravel()])\n",
    "    Theta1P=Theta1+epsilon\n",
    "    Theta2P=Theta2+epsilon\n",
    "    Theta1M=Theta1-epsilon\n",
    "    Theta2M=Theta2-epsilon\n",
    "    gradP=costNN(Theta1P,Theta2P,opLayer,y_matrix,lambda_=1)\n",
    "    gradM=costNN(Theta1M,Theta2M,opLayer,y_matrix,lambda_=1)\n",
    "    grad=(gradP-gradM)/(2*epsilon)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9e42d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,a2,opLayer,y_matrix = forProp(X,Theta1,Theta2,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4a106bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "54157640",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = costNN(Theta,opLayer,y_matrix,lambda_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a12966cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6901490522003035"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "41bfbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = backProp(a1,a2,opLayer,Theta,lambda_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9bfa6016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.36298844e-02,  3.45481146e-05, -4.40897397e-03, ...,\n",
       "        2.94399222e-01,  1.52300801e-01,  4.10992489e-02])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae848cc",
   "metadata": {},
   "source": [
    "**Cost Minimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bef48adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3c36500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1=randInitializeWeights(64,15)\n",
    "Theta2 = randInitializeWeights(15,10)\n",
    "Theta=np.concatenate([Theta1.ravel(), Theta2.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677bc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "da39cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradientd descent\n",
    "\n",
    "lr=0.1\n",
    "for _ in range(500):\n",
    "    grad = backProp(a1,a2,opLayer,Theta,lambda_=1)\n",
    "    Theta-=lr*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "647fe7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.11414833,  -0.01718867,  -0.09166087, ..., -14.56119054,\n",
       "        -7.55269511,  -2.09414309])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f779c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = np.reshape(Theta[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "Theta2 = np.reshape(Theta[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "738bbd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-18.6789052 , -14.37949832,  -8.25115765,  -0.68203683,\n",
       "         -6.77875487,  -1.40303212,  -9.99341328,  -7.89081968,\n",
       "         -0.14825938,  -1.13886675,  -5.05453492, -15.94403198,\n",
       "        -17.78496616, -13.70938283,  -8.67481129,  -1.90808037],\n",
       "       [-19.71897991, -14.57708415, -10.05053021,  -0.72679944,\n",
       "         -7.50131765,  -1.23571992,  -9.15614487, -10.4547295 ,\n",
       "         -2.14146113,  -1.49679597,  -5.80149364, -13.53860681,\n",
       "        -18.86108143, -14.0942608 ,  -5.31153493,  -1.82940092],\n",
       "       [-20.54930029, -14.98120861,  -9.1333047 ,  -0.70779136,\n",
       "         -5.87272869,  -1.25028862,  -7.52533913, -11.06099135,\n",
       "         -2.5721959 ,  -1.32954809,  -6.23678689, -14.47404271,\n",
       "        -19.69198806, -13.61841865,  -8.76638981,  -2.0417525 ],\n",
       "       [-18.6123323 , -13.46195418,  -7.9748491 ,  -0.3576486 ,\n",
       "         -6.36356553,  -1.1883503 ,  -6.30647087,  -9.41131136,\n",
       "         -2.2477354 ,  -1.38963633,  -4.91251237, -13.36287199,\n",
       "        -17.73772478, -11.89556915,  -7.03331066,  -2.03884404],\n",
       "       [-18.78996306, -15.83603921,  -7.37172323,  -0.80630226,\n",
       "         -7.31308789,  -1.09849429, -10.10224499,  -9.3358665 ,\n",
       "         -2.5854532 ,  -1.19239637,  -5.40691829, -13.46740746,\n",
       "        -17.91473532, -13.38707835,  -6.85580182,  -1.96646454]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e656cba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 270 and the array at index 1 has size 1797",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-65988d84a507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTheta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-195-2245a0d225c9>\u001b[0m in \u001b[0;36mforProp\u001b[0;34m(X, Theta1, Theta2, m)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTheta1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTheta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'''Forward propagation for 3 layers Neural Network'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 270 and the array at index 1 has size 1797"
     ]
    }
   ],
   "source": [
    "_,_,op,_=forProp(X,Theta1,Theta2,y_val.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "68cb3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[4].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "61031c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_v = y_val.reshape(-1) #convert into single row vector\n",
    "y_v = np.eye(num_labels)[y_v] #encode output layer with 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1f0c94b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda4edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98a56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a41da6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cdf8d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    \"\"\"\n",
    "    Implements the neural network cost function and gradient for a two layer neural \n",
    "    network which performs classification. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_params : array_like\n",
    "        The parameters for the neural network which are \"unrolled\" into \n",
    "        a vector. This needs to be converted back into the weight matrices Theta1\n",
    "        and Theta2.\n",
    "    \n",
    "    input_layer_size : int\n",
    "        Number of features for the input layer. \n",
    "    \n",
    "    hidden_layer_size : int\n",
    "        Number of hidden units in the second layer.\n",
    "    \n",
    "    num_labels : int\n",
    "        Total number of labels, or equivalently number of units in output layer. \n",
    "    \n",
    "    X : array_like\n",
    "        Input dataset. A matrix of shape (m x input_layer_size).\n",
    "    \n",
    "    y : array_like\n",
    "        Dataset labels. A vector of shape (m,).\n",
    "    \n",
    "    lambda_ : float, optional\n",
    "        Regularization parameter.\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The computed value for the cost function at the current weight values.\n",
    "    \n",
    "    grad : array_like\n",
    "        An \"unrolled\" vector of the partial derivatives of the concatenatation of\n",
    "        neural network weights Theta1 and Theta2.\n",
    "    \n",
    "        \"\"\"\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                        (num_labels, (hidden_layer_size + 1)))\n",
    "\n",
    "    # Setup some useful variables\n",
    "    m = y.size\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    #1. Forward propagation\n",
    "    #Input Layer\n",
    "    #Adding bias term (a1=X)\n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    #Hidden layer\n",
    "    a2=sigmoid(a1.dot(Theta1.T))\n",
    "    a2=np.concatenate([np.ones((m,1)),a2],axis=1) #adding bias term in second layer\n",
    "    \n",
    "    #Output layer\n",
    "    a3=sigmoid(a2.dot(Theta2.T))\n",
    "    y_matrix = y.reshape(-1) #convert into single row vector\n",
    "    y_matrix = np.eye(num_labels)[y_matrix] #encode output layer with 1 and 0\n",
    "    \n",
    "    #Calculating cost\n",
    "    J = (-1/m) * (np.sum(y_matrix * np.log(a3) + (1-y_matrix) * np.log(1-a3))) #cost without regularization terms\n",
    "    #Adding regularization terms\n",
    "    reg = (lambda_/(2*m)) * (np.sum(np.square(Theta1[:, 1:])) + np.sum(np.square(Theta2[:, 1:])))\n",
    "    J = J + reg\n",
    "    \n",
    "    # Part 2 : Back Propagation\n",
    "    del3 = a3-y_matrix\n",
    "    \n",
    "    del2 = np.dot(del3, Theta2[:, 1:]) * sigmoidGradient(np.dot(a1, Theta1.T))  # exclude bias unit because it has no connection with input layer\n",
    "    \n",
    "    Delta1 = np.dot(del2.T, a1)  \n",
    "    Delta2 = np.dot(del3.T, a2)\n",
    "    \n",
    "    #Calculating gradient term\n",
    "    Theta2_grad = (1/m) * Delta2\n",
    "    Theta1_grad = (1/m) * Delta1\n",
    "    \n",
    "    # Add regularization terms excluding the Theta columns for the bias units\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_/m) * Theta2[:, 1:]\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_/m) * Theta1[:, 1:]\n",
    "    \n",
    "    \n",
    "    # ================================================================\n",
    "    # Unroll gradients\n",
    "    # grad = np.concatenate([Theta1_grad.ravel(order=order), Theta2_grad.ravel(order=order)])\n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1c8dceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options= {'maxiter': 100}\n",
    "\n",
    "#  You should also try different values of lambda\n",
    "lambda_ = 1\n",
    "\n",
    "# Create \"short hand\" for the cost function to be minimized\n",
    "costFunction = lambda p: nnCostFunction(p, input_layer_size,\n",
    "                                        hidden_layer_size,\n",
    "                                        num_labels, X, y, lambda_)\n",
    "\n",
    "# Now, costFunction is a function that takes in only one argument\n",
    "# (the neural network parameters)\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_nn_params,\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# get the solution of the optimization\n",
    "nn_params = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c15040a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
    "                    (hidden_layer_size, (input_layer_size + 1)))\n",
    "\n",
    "Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
    "                    (num_labels, (hidden_layer_size + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2e3cd2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.47475045e-02, -4.16399006e-02, -5.17238432e-02,\n",
       "         3.33281776e-02,  1.10000424e-01,  5.43311045e-02,\n",
       "         1.25290699e-01,  4.22343000e-02, -3.08199524e-03,\n",
       "        -2.12033932e-02, -2.24668969e-02,  1.03816186e-01,\n",
       "         5.96697501e-02, -2.75225493e-03,  3.71711848e-02,\n",
       "         5.65436484e-02, -6.01393416e-02, -6.24407621e-02,\n",
       "         2.23809910e-02,  7.10205610e-02,  7.27797385e-02,\n",
       "         1.05794919e-01,  1.07607524e-01,  3.83802495e-02,\n",
       "         4.38133269e-02, -3.45743476e-02, -3.87083644e-03,\n",
       "         2.53033646e-02,  1.14128721e-02,  6.99721280e-02,\n",
       "        -1.11938551e-02,  1.18754271e-02, -1.36408466e-02,\n",
       "        -1.25455595e-03,  7.33966760e-03,  2.56267642e-02,\n",
       "         2.58264038e-02,  1.20828260e-01,  1.45457794e-01,\n",
       "         2.39812873e-02,  2.43492257e-02, -7.34564465e-02,\n",
       "        -2.25660579e-02,  3.02556309e-02,  1.01580909e-01,\n",
       "        -5.52110793e-03,  5.19404108e-02,  1.15060489e-01,\n",
       "         3.88146794e-03,  2.22552367e-02, -6.83730556e-02,\n",
       "         1.10881703e-01,  7.05055628e-02,  7.05097471e-02,\n",
       "         3.15240650e-02, -2.40035002e-02, -1.55837160e-02,\n",
       "         3.54175856e-02,  7.28052608e-02,  2.54978208e-02,\n",
       "         1.00095470e-01,  8.96014727e-02,  6.02267088e-02,\n",
       "         3.96832834e-02,  6.67045649e-02],\n",
       "       [-8.59565911e-02,  5.10842005e-02, -4.72160490e-02,\n",
       "        -7.96127509e-03,  1.39651946e-01,  5.90276298e-02,\n",
       "         1.30207230e-01,  3.47458705e-02,  4.49082803e-02,\n",
       "        -9.15405922e-02,  4.00604351e-02,  1.16239463e-01,\n",
       "         6.52526868e-02,  3.90763862e-02,  1.20547788e-01,\n",
       "        -2.13590170e-02,  3.80892456e-02,  1.07813636e-02,\n",
       "        -3.14918638e-04,  1.90434793e-01,  1.39571516e-01,\n",
       "         4.03840837e-02, -7.65417460e-03, -2.63657348e-02,\n",
       "        -1.99410950e-02,  3.99496586e-02,  1.14367618e-01,\n",
       "         6.17309878e-02,  1.47582692e-01,  1.12819042e-01,\n",
       "         1.02662718e-01, -4.84294918e-02, -1.98964667e-02,\n",
       "        -5.02279352e-02, -1.08487087e-02,  7.90316105e-02,\n",
       "         1.24091938e-01,  4.12080621e-02,  4.14717955e-02,\n",
       "        -1.16611503e-03,  3.16209487e-02,  6.66014285e-02,\n",
       "         2.34458677e-02,  1.53008489e-01,  4.25366041e-02,\n",
       "         1.68834224e-02,  6.75365264e-02,  9.46774236e-03,\n",
       "         6.43776691e-02, -3.15632639e-02,  1.61003241e-02,\n",
       "         1.03104222e-01,  9.99339034e-02, -1.47949860e-02,\n",
       "         2.13537797e-01,  1.53261827e-01, -5.32857316e-02,\n",
       "        -4.04281637e-02,  5.42516322e-03,  1.35772958e-01,\n",
       "         2.35975708e-01,  9.15854575e-02,  1.05687112e-01,\n",
       "         8.82623940e-02, -1.90426936e-02],\n",
       "       [ 6.36804253e-02, -6.51593516e-02,  2.18463743e-02,\n",
       "         1.10312535e-01,  1.79343742e-01,  1.53221882e-02,\n",
       "         3.69508244e-02, -4.43566174e-02, -8.65853472e-03,\n",
       "         9.53370611e-03, -5.96065063e-02,  3.06863471e-02,\n",
       "         1.54778443e-01,  8.12801446e-02,  6.53469795e-02,\n",
       "         6.72240735e-02,  4.76493259e-02, -8.57414711e-02,\n",
       "         5.52132430e-02,  1.12833677e-01, -2.45403352e-02,\n",
       "         1.12936518e-01,  3.10768856e-02, -2.42418764e-02,\n",
       "         3.24354157e-02, -7.43246183e-02,  4.03014276e-02,\n",
       "         1.08372903e-01,  9.03028016e-02,  5.91946055e-02,\n",
       "         4.41408639e-02,  6.40872103e-02,  1.29721167e-02,\n",
       "        -7.91708011e-02,  2.20897392e-02,  8.51781458e-02,\n",
       "         1.13274633e-02,  1.57121750e-01,  1.14284415e-01,\n",
       "         3.11998461e-02,  4.88111794e-02, -8.02066779e-02,\n",
       "         7.42518742e-02,  8.86952174e-02,  1.11807599e-01,\n",
       "        -1.74654119e-02, -1.12742246e-02, -4.42259506e-02,\n",
       "        -1.97787942e-02, -1.48876523e-02,  1.64216346e-02,\n",
       "        -2.24116968e-02,  3.03594631e-03,  1.24749544e-01,\n",
       "         5.83896454e-02,  8.83579755e-02, -9.08839842e-02,\n",
       "         1.02115375e-02,  8.40147574e-02,  5.54146851e-02,\n",
       "         2.98788828e-02,  1.22735395e-01,  2.92322771e-02,\n",
       "         5.18204945e-02, -8.21405292e-02],\n",
       "       [ 4.10719022e-02, -8.87260738e-02,  4.83121977e-02,\n",
       "         1.77379360e-02,  1.55767248e-02,  8.27608431e-02,\n",
       "        -5.10605058e-02,  3.78727843e-02,  9.52081277e-02,\n",
       "         5.21481728e-02,  2.11753236e-02, -9.81785078e-04,\n",
       "         1.33979912e-01,  9.67744507e-02, -3.73477566e-02,\n",
       "         6.64662683e-02,  4.73332633e-03, -1.46281935e-02,\n",
       "         7.33406789e-02,  7.13221300e-02,  4.79032787e-02,\n",
       "        -3.53304794e-02,  7.74284653e-03,  8.19036450e-02,\n",
       "        -5.99203727e-02, -1.63068439e-02,  1.20281973e-01,\n",
       "         4.33032170e-02,  1.28552687e-01,  1.15415493e-01,\n",
       "        -2.70162451e-02,  1.30256383e-02,  4.47659607e-04,\n",
       "        -3.63791677e-02, -5.64117974e-02,  3.16786238e-02,\n",
       "        -1.79823244e-02,  6.44606045e-03,  1.30136109e-01,\n",
       "         1.04517412e-01, -8.67369267e-02, -3.85795022e-02,\n",
       "         1.08639774e-01,  7.80361318e-02,  7.48409341e-02,\n",
       "        -4.40421105e-02,  6.39487935e-02,  1.34584079e-01,\n",
       "        -2.40657886e-02, -7.69220354e-02, -3.75331505e-03,\n",
       "         1.60745854e-01,  4.20653006e-02,  1.24841944e-01,\n",
       "         1.31892489e-01, -1.51649022e-02, -8.99519198e-03,\n",
       "         4.19784508e-02, -1.69604657e-02, -3.28422668e-02,\n",
       "         1.79744167e-01,  1.23150268e-01,  1.33857077e-01,\n",
       "        -6.71307418e-02, -4.37190858e-02],\n",
       "       [-7.10675559e-02, -8.23481999e-02, -1.50185683e-01,\n",
       "        -1.59436201e+00, -7.42536366e-01, -7.13877557e-01,\n",
       "        -8.82221050e-01, -1.05199905e+00,  1.03228400e-01,\n",
       "         2.83358587e-02, -1.23699046e+00, -1.34532617e+00,\n",
       "        -6.07535532e-01, -1.01815667e+00, -6.36920797e-02,\n",
       "        -8.82192502e-01,  1.05582243e-01, -3.75929147e-02,\n",
       "        -3.63768653e-01,  9.25287925e-01,  1.54113808e+00,\n",
       "         4.86667704e-01, -5.43792748e-01, -5.79468140e-01,\n",
       "         1.12175248e-01,  4.26329539e-02,  2.93342605e-01,\n",
       "         1.04689151e+00,  6.63445722e-01,  2.84757125e-01,\n",
       "        -2.40124567e-01, -8.50990818e-01,  3.04608039e-02,\n",
       "         8.18416080e-02, -1.00833677e-01,  1.05056080e-01,\n",
       "         5.36608374e-01,  9.24149452e-01,  4.21282501e-01,\n",
       "        -4.52722064e-01, -9.15688246e-02,  6.26738085e-02,\n",
       "        -6.55475323e-01,  4.21378318e-01,  9.98776054e-01,\n",
       "         1.36818048e+00,  6.76839885e-01,  2.84958827e-01,\n",
       "         2.25293195e-02, -8.55457118e-03,  8.52576521e-02,\n",
       "        -3.40891145e-01, -1.84012563e-01, -5.96925910e-01,\n",
       "        -2.58324485e-01, -3.57818867e-02,  1.32459901e-02,\n",
       "         8.15477534e-02, -1.72875274e-01, -1.56095558e+00,\n",
       "        -6.40388793e-01,  7.49397536e-02,  3.06577344e-01,\n",
       "        -6.56657296e-01,  1.27237457e-01],\n",
       "       [-3.72680635e-02, -2.50574267e-02,  6.71844213e-02,\n",
       "        -1.30774266e-01, -7.00290869e-02, -1.13292054e-01,\n",
       "         9.24493984e-03,  6.81137625e-03,  5.86208620e-02,\n",
       "        -3.22268966e-02, -3.92991051e-02, -1.17529409e-01,\n",
       "        -1.26208558e-01, -1.50709432e-01, -1.36105040e-01,\n",
       "         5.90794047e-02,  7.65749425e-02, -2.96822626e-02,\n",
       "         4.61715932e-03, -1.76040188e-01, -1.77792328e-01,\n",
       "        -1.10498087e-01, -1.19150920e-01,  4.43643845e-02,\n",
       "         6.09342701e-02,  4.07865319e-02,  4.63845908e-02,\n",
       "        -1.45049528e-01, -1.52785272e-01, -1.84878946e-01,\n",
       "        -1.28988701e-01, -1.05677020e-01, -7.79127014e-02,\n",
       "         2.02612374e-02, -7.16923626e-02, -1.12168351e-01,\n",
       "        -1.98773301e-01, -1.15753888e-01, -1.73894513e-01,\n",
       "        -8.06712836e-02,  4.69407635e-02,  1.15612434e-02,\n",
       "        -6.42827104e-02, -1.07350435e-01, -9.30123909e-02,\n",
       "        -6.65750610e-02, -8.40091643e-02, -9.03293466e-02,\n",
       "         4.74388688e-02,  5.35646551e-02, -6.58488765e-02,\n",
       "        -3.34485304e-02, -1.38491162e-01, -8.80058303e-02,\n",
       "        -1.47311944e-01, -7.51914920e-02,  8.20750675e-02,\n",
       "         3.08905271e-02,  5.15088012e-02, -3.40633933e-03,\n",
       "        -2.03054284e-01, -1.52131639e-01, -2.62708363e-02,\n",
       "         6.47339998e-03, -9.94868410e-02],\n",
       "       [-8.96782982e-02, -3.00095788e-02,  8.54111103e-02,\n",
       "         1.59367167e-02,  2.96144339e-02,  5.20867531e-02,\n",
       "        -2.91330914e-02, -1.28803020e-02, -5.44380881e-02,\n",
       "         6.64601204e-02, -1.14790413e-03,  1.36281482e-02,\n",
       "         1.81179730e-01,  2.41466461e-02,  1.24824875e-01,\n",
       "        -7.65091805e-02,  4.09384472e-02, -3.18511076e-03,\n",
       "        -3.22772356e-04, -1.03803426e-02, -2.35240678e-02,\n",
       "         2.76551539e-03,  1.35747341e-01,  3.40046579e-02,\n",
       "        -2.49762490e-02,  2.20266778e-02, -4.21667112e-02,\n",
       "         1.35501299e-02,  3.69973963e-02,  1.41159746e-01,\n",
       "         4.32739255e-02, -2.96897712e-02,  8.55935518e-02,\n",
       "         6.08880685e-02, -1.59285713e-02,  1.70589809e-01,\n",
       "         1.85390322e-01,  6.93934638e-02,  1.02763473e-01,\n",
       "         6.28735314e-04, -4.71096300e-02, -7.95594514e-02,\n",
       "        -3.36655311e-02,  2.48549951e-02,  3.90751557e-02,\n",
       "        -5.77839591e-03,  1.63508402e-01, -3.24114833e-02,\n",
       "         2.57086153e-02, -1.15069981e-02, -1.22375542e-02,\n",
       "         2.49297349e-02,  1.42742045e-01,  1.26105956e-02,\n",
       "        -1.96921701e-02,  1.26696538e-01,  7.25245788e-02,\n",
       "        -4.33977346e-02,  5.35367491e-03, -5.32662474e-02,\n",
       "         3.95076506e-03,  1.64841690e-01,  4.10484025e-02,\n",
       "         5.01040562e-02,  8.46620852e-02],\n",
       "       [-7.26120768e-02, -9.21489502e-02, -9.23254624e-02,\n",
       "        -8.15061238e-03, -4.84455267e-02, -1.20925404e-01,\n",
       "        -9.47102268e-02, -1.18975133e-02,  6.47299968e-02,\n",
       "         2.97955612e-02, -6.83546505e-02, -4.86391601e-02,\n",
       "        -1.79825967e-01, -1.80146110e-01, -8.68301440e-02,\n",
       "        -7.89993353e-02,  3.72827353e-02, -2.95038995e-02,\n",
       "        -6.30885976e-02,  1.73192300e-02, -1.37073088e-01,\n",
       "        -4.80613217e-02, -2.03407415e-01,  2.74179382e-02,\n",
       "        -5.27729098e-02, -7.82709731e-02,  1.22959365e-02,\n",
       "        -1.86813870e-02, -3.83528842e-02, -1.94163798e-01,\n",
       "        -1.33932279e-01, -4.12494225e-02, -4.14490439e-02,\n",
       "         5.98707762e-02, -8.69457883e-02, -3.61354689e-02,\n",
       "         1.63440719e-02, -1.61756563e-02, -1.50402346e-01,\n",
       "        -1.37782346e-01,  9.10282277e-02,  7.32853546e-02,\n",
       "         6.96644488e-02, -6.16797334e-02, -3.79649225e-03,\n",
       "        -1.18048643e-01, -9.43993468e-02,  3.08374931e-02,\n",
       "        -7.13980431e-02,  7.53441575e-02, -4.38767889e-03,\n",
       "        -7.19812613e-02, -1.27042253e-01, -2.49186066e-03,\n",
       "        -6.36397125e-02,  3.52047122e-02,  6.82292842e-02,\n",
       "         8.05048154e-02, -3.96006690e-02, -8.48573615e-02,\n",
       "        -9.32995865e-02, -9.62092615e-02,  3.34287726e-02,\n",
       "        -2.50027221e-02, -4.93104193e-03],\n",
       "       [ 5.58412921e-02, -1.87650568e-02,  9.86605107e-02,\n",
       "         4.83922459e-02,  2.45700735e-01,  2.60291577e-01,\n",
       "         9.42142806e-02, -2.37017223e-03,  5.88073344e-02,\n",
       "         4.64500922e-03, -4.42747294e-02,  3.76229989e-01,\n",
       "         3.00445574e-01,  1.88325709e-01,  2.58807367e-01,\n",
       "         2.69884752e-02, -6.68685488e-02,  1.26285175e-02,\n",
       "         1.03792527e-01,  2.68554799e-01,  9.93315368e-02,\n",
       "         1.47478273e-01,  2.14835794e-01,  9.22478962e-02,\n",
       "        -2.67589251e-02,  5.74985254e-02,  8.35845291e-02,\n",
       "         1.52130858e-01,  1.94700602e-01,  3.07148354e-01,\n",
       "         2.11915767e-01,  1.48900174e-02,  2.07281372e-03,\n",
       "         4.98129204e-02, -1.21020545e-02,  2.62960898e-01,\n",
       "         1.52975057e-01,  2.22752818e-01,  1.96544069e-01,\n",
       "         4.07650657e-02,  2.88951763e-02, -8.76659015e-02,\n",
       "         9.04266174e-02,  1.66209039e-01,  2.43165310e-01,\n",
       "         1.58054102e-01,  1.36683508e-01,  2.97647944e-02,\n",
       "         5.78321249e-02, -1.49872895e-03,  2.44253407e-03,\n",
       "         1.43038726e-01,  1.91745691e-01,  3.12455143e-01,\n",
       "         1.78825795e-01,  1.55823821e-01,  3.13605107e-02,\n",
       "         6.87915877e-02,  7.21364251e-02,  2.24968415e-01,\n",
       "         3.32980920e-01,  3.28720400e-01,  1.86058685e-01,\n",
       "         4.89763651e-02,  4.46088310e-02],\n",
       "       [ 7.38667988e-02, -8.71550446e-02,  8.98362492e-03,\n",
       "         1.44059247e-01,  1.59529736e-01,  1.88555851e-01,\n",
       "         8.16490741e-02,  6.20635531e-03, -7.03860029e-02,\n",
       "         5.21083266e-03,  2.02842591e-02,  1.97300191e-01,\n",
       "         2.32387104e-01,  1.10902586e-01,  2.19145472e-02,\n",
       "         6.93170421e-02,  4.28535096e-02,  8.73707474e-02,\n",
       "         1.23483719e-01,  1.71779144e-01,  1.84670612e-01,\n",
       "         1.05183768e-01,  3.78673814e-02,  3.11915180e-03,\n",
       "        -7.42571295e-02,  3.26040795e-02, -4.46761417e-03,\n",
       "         1.79056318e-01,  2.94422743e-01,  9.72205818e-02,\n",
       "         4.55270496e-02, -5.26679702e-03,  8.40677585e-02,\n",
       "         7.80293100e-02, -9.64551701e-03,  2.79883360e-01,\n",
       "         2.47770991e-01,  1.95597847e-01,  2.40499776e-01,\n",
       "         1.17367460e-01, -2.13814103e-02,  3.08766321e-02,\n",
       "         6.03094435e-02,  9.88114132e-02,  1.00371163e-01,\n",
       "         1.48840956e-01,  9.60628709e-02,  2.12181186e-02,\n",
       "         8.66409587e-02, -7.64740231e-03,  4.79287855e-02,\n",
       "         8.96509700e-02,  3.00535912e-01,  2.20646511e-01,\n",
       "         8.77502268e-02, -1.46524138e-02,  8.84635587e-02,\n",
       "         8.45686719e-02,  2.96655354e-02,  4.22007088e-03,\n",
       "         1.63429932e-01,  2.87926666e-01,  1.97462136e-01,\n",
       "         2.57381346e-02, -1.83344952e-02],\n",
       "       [-5.00119245e-02, -7.33009083e-02, -7.30062357e-02,\n",
       "         9.45257847e-02,  8.86697860e-02, -1.47036663e-02,\n",
       "        -3.44554432e-02,  3.49712345e-02,  5.16224856e-02,\n",
       "         5.98321402e-02, -6.13900140e-02,  1.11074398e-01,\n",
       "        -8.16508495e-03,  5.01444034e-02,  3.02317466e-02,\n",
       "         9.18280962e-02,  3.14208606e-02,  1.67392807e-02,\n",
       "         8.14899579e-03,  8.33242672e-02, -3.28174452e-02,\n",
       "        -7.42416888e-02,  9.61321348e-02,  4.82525894e-03,\n",
       "        -3.30535831e-02, -2.58949877e-02,  6.96043828e-02,\n",
       "         1.98172055e-02,  8.83966944e-02,  1.52957816e-02,\n",
       "         9.00079632e-02, -6.93347972e-02, -3.71781743e-03,\n",
       "        -6.56913366e-03, -2.98685884e-02,  1.25735662e-01,\n",
       "         1.09721998e-01,  2.67168894e-02, -2.92696283e-02,\n",
       "        -4.03989882e-02, -4.44267321e-02, -2.95949442e-03,\n",
       "        -1.90138594e-02,  8.42390521e-02,  2.28242427e-02,\n",
       "         1.06498989e-01,  1.32476655e-01, -3.69468966e-02,\n",
       "         2.23764951e-02,  6.69048763e-02,  8.77020368e-02,\n",
       "        -2.46831781e-02,  7.17420192e-02, -5.21233761e-02,\n",
       "         9.61453868e-02, -7.27664017e-02,  4.58875732e-02,\n",
       "         9.35392126e-02,  5.37348388e-04, -4.61343994e-02,\n",
       "         4.76378113e-02,  6.50036188e-02,  4.80344911e-02,\n",
       "        -6.19657069e-02,  7.57733093e-02],\n",
       "       [ 4.28559090e-02, -8.66744520e-02,  4.07186807e-02,\n",
       "         1.56626565e-02,  6.79574227e-02,  1.49928520e-01,\n",
       "         1.52413740e-01,  8.94799360e-02, -7.45213323e-02,\n",
       "         3.20387032e-02,  7.05352487e-02,  9.23282091e-02,\n",
       "         2.44325345e-01,  9.38950014e-02,  4.12472590e-02,\n",
       "         2.68025195e-02,  3.86815026e-02, -4.94377688e-02,\n",
       "         2.63069669e-03,  1.18699833e-01,  1.70429240e-01,\n",
       "         1.59998632e-01,  4.27363639e-02, -3.32915782e-02,\n",
       "         4.80816457e-03,  5.20901035e-02,  4.68930291e-02,\n",
       "         8.79509591e-02,  1.43574518e-01,  1.97275764e-01,\n",
       "         8.61332942e-02,  9.07399687e-02,  8.49768829e-02,\n",
       "         7.92179787e-02,  6.13213325e-02,  1.90427083e-02,\n",
       "         8.44736035e-02,  8.53101210e-02,  1.19878988e-01,\n",
       "        -1.21741601e-02,  4.93304594e-02, -7.39430333e-02,\n",
       "         6.21107348e-02,  7.55486199e-02,  1.50067330e-01,\n",
       "         7.28015809e-02,  1.13595551e-01,  4.37874330e-02,\n",
       "         9.02336403e-02,  4.95638943e-02,  1.66938906e-02,\n",
       "         3.02051656e-02,  2.03131228e-01,  6.45598191e-02,\n",
       "         1.35747241e-01,  1.27887300e-01, -5.12230408e-02,\n",
       "        -5.30313375e-02,  7.20869975e-02,  1.42495584e-01,\n",
       "         1.16898956e-01,  9.78044238e-02,  1.87665654e-02,\n",
       "         1.19086586e-01,  6.89985079e-02],\n",
       "       [ 7.16483173e-02,  2.71572834e-03, -7.94565014e-02,\n",
       "        -1.97944377e-01, -2.59339310e-01, -1.62096112e-01,\n",
       "        -4.62177356e-02,  3.25694319e-02, -6.91225222e-02,\n",
       "        -1.59218366e-02, -8.86161876e-02, -2.60855767e-01,\n",
       "        -1.74628301e-01, -1.89978530e-01, -2.07159884e-01,\n",
       "        -1.19700500e-01,  7.10246120e-03, -3.00346801e-02,\n",
       "        -6.45988177e-02, -1.92774652e-01, -1.34874597e-01,\n",
       "        -1.37899373e-01, -2.77328750e-01,  3.50840374e-02,\n",
       "         7.98200276e-02,  9.97267216e-03, -7.86326649e-02,\n",
       "        -5.47681350e-02, -1.87700268e-01, -1.75173367e-01,\n",
       "        -1.16058948e-01, -5.18533194e-02, -5.80774336e-02,\n",
       "         8.85057249e-02, -1.11613665e-01, -1.12514400e-01,\n",
       "        -2.48172236e-01, -2.54821313e-01, -1.00619863e-01,\n",
       "        -7.46656106e-02, -7.94545316e-02, -5.86132311e-02,\n",
       "         5.39178029e-02, -1.21873789e-02, -1.94995519e-01,\n",
       "        -1.19286866e-01, -2.21678876e-01, -7.46507554e-03,\n",
       "        -1.67287453e-02,  7.97110354e-02, -4.62778402e-02,\n",
       "        -4.42599412e-02, -1.70376225e-01, -1.88384863e-01,\n",
       "        -1.05216383e-01, -1.10968049e-01, -5.67155557e-02,\n",
       "        -5.85931630e-02,  8.22255127e-02, -1.05333123e-01,\n",
       "        -1.81892162e-01, -1.84610256e-01, -9.26075252e-02,\n",
       "        -2.09341399e-02,  8.12579328e-02],\n",
       "       [ 6.14337250e-02, -5.04329723e-02, -8.51474021e-02,\n",
       "         4.28184471e-02,  1.87189802e-01,  1.81082243e-01,\n",
       "         1.70529406e-01,  8.56343958e-02, -7.48408256e-02,\n",
       "         8.60676457e-02,  4.31695142e-02,  1.92689670e-01,\n",
       "         1.87658389e-01,  2.16291761e-01,  2.28719075e-01,\n",
       "         7.27334797e-02,  9.18481328e-02,  3.92558072e-02,\n",
       "         1.12217790e-01,  8.52377647e-02,  1.48972456e-01,\n",
       "         1.67425266e-01,  8.08206396e-02,  1.03170262e-01,\n",
       "         2.35187660e-02, -7.66951382e-02,  5.45112498e-02,\n",
       "         1.23041996e-01,  8.77851974e-02,  1.12071620e-01,\n",
       "         1.14201076e-01,  7.07095432e-02, -3.33407137e-02,\n",
       "        -3.76075680e-02,  8.61494753e-02,  1.83090995e-01,\n",
       "         2.22166372e-01,  1.31190220e-01,  1.37669279e-01,\n",
       "         5.82047158e-02,  4.75172605e-02,  7.71203980e-02,\n",
       "        -3.14130711e-04,  9.43563225e-02,  2.08824715e-01,\n",
       "         1.78890731e-01,  1.19682866e-01,  1.38563621e-02,\n",
       "        -5.84387072e-02, -6.07636568e-02, -6.85758853e-02,\n",
       "         5.17446771e-02,  2.65938323e-01,  1.35379125e-01,\n",
       "         5.74563249e-02,  1.49262838e-01, -4.92743396e-02,\n",
       "        -4.50631602e-02, -5.35121313e-02,  2.00995349e-01,\n",
       "         1.47401835e-01,  2.37869328e-01,  2.17646668e-01,\n",
       "         8.73514600e-02,  7.94956449e-02],\n",
       "       [-7.44526243e-03,  3.39992747e-02,  1.62873038e-01,\n",
       "        -1.26104904e-01, -2.38377229e-02,  7.22432612e-02,\n",
       "        -5.00991629e-01,  3.40468292e-01,  2.87111658e-01,\n",
       "         1.44496541e-02,  4.29714138e-01,  8.82899171e-02,\n",
       "         4.83687629e-01,  2.87212443e-01, -6.58767794e-01,\n",
       "         3.91290046e-01,  2.25825940e-01, -8.67699580e-02,\n",
       "         2.10871282e-02, -3.84827415e-01, -3.97168534e-01,\n",
       "        -3.66193323e-01, -6.01146702e-01,  3.22699188e-01,\n",
       "         2.96098369e-02, -3.34676014e-02,  1.74934047e-01,\n",
       "        -6.95779225e-01, -1.41647196e+00, -4.29373517e-01,\n",
       "        -9.74575681e-02,  1.40198217e+00,  5.12918357e-02,\n",
       "        -2.90686372e-02,  9.63728651e-01,  5.24047379e-01,\n",
       "        -4.44304934e-01,  1.34593763e-02,  6.92596815e-01,\n",
       "         7.39188404e-01, -8.00635886e-02, -6.50156549e-02,\n",
       "         4.41640341e-01,  7.17838727e-01,  9.73910580e-01,\n",
       "        -7.97032749e-02, -7.75844464e-02, -7.48794907e-02,\n",
       "        -2.98545100e-03,  3.75440277e-02,  2.92121906e-01,\n",
       "        -1.81921951e-01,  9.19217347e-01,  1.67546224e-01,\n",
       "         7.50291107e-02,  4.16380204e-03, -2.21113621e-01,\n",
       "        -2.85883439e-02,  1.55307350e-01,  3.15999803e-01,\n",
       "        -2.04269413e-01, -3.02827676e-01,  1.19822874e-01,\n",
       "         5.43337941e-01,  1.87432298e-01]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ff2a6ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,op,_=forProp(x_val,Theta1,Theta2,y_val.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "125df724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(op[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9c60c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc312c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
